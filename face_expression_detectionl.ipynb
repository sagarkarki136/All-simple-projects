{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_SQ-UL6lJxU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HSGdl9cpQaT"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('/content/drive/My Drive/all/Face_expression_data/fer2013.zip') as zp:\n",
    "  zp.extractall('/content/drive/My Drive/all/Face_expression_data')             #extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9VVkTqz3ypqI",
    "outputId": "92a2c451-f225-4a82-cf59-90a8dd5c691a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#get all the imports necessary\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try :\n",
    " %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.stats import rankdata\n",
    "from shutil import copyfile, move\n",
    "\n",
    "\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import resnet_v2\n",
    "from keras import utils\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Th1CSMO5rYhg",
    "outputId": "885c80b3-2ca8-450e-fed7-41ad6f7cfd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "#read CSV\n",
    "with open(\"/content/drive/My Drive/all/Face_expression_data/fer2013/fer2013.csv\") as f:\n",
    "  content = f.readlines()\n",
    "  \n",
    "  lines = np.array(content)\n",
    "  \n",
    "  num_of_instances = lines.size\n",
    "  print(\"number of instances: \",num_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vda7hSJWzJSd"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'/content/drive/My Drive/all/Face_expression_data/fer2013/fer2013.csv')\n",
    "df2=df[df['Usage']=='PrivateTest']\n",
    "df3=df[df['Usage']=='PublicTest']\n",
    "df1=df[df['Usage']=='Training']\n",
    "print(df3.shape,df2.shape,df1.shape)    #get the split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSD2A-PTzxWr"
   },
   "outputs": [],
   "source": [
    "p=df.iloc[1,1]\n",
    "val=p.split(\" \")\n",
    "val=np.array(val,'float32').reshape((48,48,1))\n",
    "\n",
    "val=tf.convert_to_tensor(val)\n",
    "\n",
    "val=tf.image.grayscale_to_rgb(val)\n",
    "pg=np.asarray(val)                                      #trial on one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdCgFEBlliab"
   },
   "outputs": [],
   "source": [
    "y=[1]\n",
    "p=utils.to_categorical(y,num_classes=3)\n",
    "p=np.array(p)                                          #trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RhtuyaNzD3r"
   },
   "outputs": [],
   "source": [
    "#Generate data and labels\n",
    "\n",
    "x_train, y_train, x_test, y_test,x_val,y_val = [], [], [], [],[],[]\n",
    " \n",
    "for i in range(1,num_of_instances):\n",
    " try:\n",
    "  emotion, img, usage = lines[i].split(\",\")\n",
    "  \n",
    "  val = img.split(\" \")\n",
    "  val=np.array(val,'float32').reshape((48,48,1))\n",
    "  val=tf.convert_to_tensor(val)\n",
    "  val=tf.image.grayscale_to_rgb(val)\n",
    "  val=np.asarray(val)\n",
    "  emotion = utils.to_categorical(emotion, num_classes=7)\n",
    "\n",
    "  if 'Training' in usage:\n",
    "    y_train.append(emotion)\n",
    "    x_train.append(val) \n",
    "  elif 'PrivateTest' in usage:\n",
    "    y_val.append(emotion)\n",
    "    x_val.append(val)\n",
    "  elif 'PublicTest' in usage:\n",
    "    y_test.append(emotion)\n",
    "    x_test.append(val)\n",
    "\n",
    " except:\n",
    "  print(\"\", end=\"\")\n",
    "\n",
    "x_test,x_val,x_train=np.asarray(x_test),np.asarray(x_val),np.asarray(x_train)\n",
    "y_test,y_val,y_train=np.asarray(y_test),np.asarray(y_val),np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y7UnU1duymom",
    "outputId": "25ab65f0-c3c8-40e4-e668-1b39faebec04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2cokkPL1lNn"
   },
   "outputs": [],
   "source": [
    "conv_base=resnet_v2.ResNet50V2(weights=None, include_top=False,input_shape=(48,48,1))\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(7,activation='softmax'))           #build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OM0eF85V9UdL",
    "outputId": "63082cdd-bdb9-4a06-9af3-1a250c653a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh\n",
      "dd\n",
      "Epoch 1/150\n",
      "128/128 [==============================] - 19s 152ms/step - loss: 1.8948 - accuracy: 0.2881 - val_loss: 2.1441 - val_accuracy: 0.2733\n",
      "Epoch 2/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.7883 - accuracy: 0.3291 - val_loss: 1.8990 - val_accuracy: 0.2839\n",
      "Epoch 3/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.7780 - accuracy: 0.3383 - val_loss: 1.5807 - val_accuracy: 0.2959\n",
      "Epoch 4/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.7968 - accuracy: 0.3309 - val_loss: 2.1225 - val_accuracy: 0.3257\n",
      "Epoch 5/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.7754 - accuracy: 0.3191 - val_loss: 1.8809 - val_accuracy: 0.3174\n",
      "Epoch 6/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.7652 - accuracy: 0.3470 - val_loss: 68.3806 - val_accuracy: 0.3388\n",
      "Epoch 7/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.7144 - accuracy: 0.3634 - val_loss: 2.1537 - val_accuracy: 0.3683\n",
      "Epoch 8/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.7157 - accuracy: 0.3760 - val_loss: 1.4784 - val_accuracy: 0.3544\n",
      "Epoch 9/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.8156 - accuracy: 0.3229 - val_loss: 2.2023 - val_accuracy: 0.2717\n",
      "Epoch 10/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.7053 - accuracy: 0.3597 - val_loss: 1.4423 - val_accuracy: 0.3519\n",
      "Epoch 11/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.7486 - accuracy: 0.3533 - val_loss: 1.4450 - val_accuracy: 0.2831\n",
      "Epoch 12/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.6660 - accuracy: 0.3661 - val_loss: 1.6368 - val_accuracy: 0.3126\n",
      "Epoch 13/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.6422 - accuracy: 0.3706 - val_loss: 1.3524 - val_accuracy: 0.3709\n",
      "Epoch 14/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.6758 - accuracy: 0.3637 - val_loss: 0.9519 - val_accuracy: 0.3717\n",
      "Epoch 15/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.6496 - accuracy: 0.3809 - val_loss: 1.4561 - val_accuracy: 0.3678\n",
      "Epoch 16/150\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 1.6201 - accuracy: 0.3777 - val_loss: 1.3570 - val_accuracy: 0.3491\n",
      "Epoch 17/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.6661 - accuracy: 0.3781 - val_loss: 1.5543 - val_accuracy: 0.3739\n",
      "Epoch 18/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.6544 - accuracy: 0.3835 - val_loss: 2.0118 - val_accuracy: 0.2875\n",
      "Epoch 19/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.5516 - accuracy: 0.4052 - val_loss: 1.5799 - val_accuracy: 0.4009\n",
      "Epoch 20/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.5177 - accuracy: 0.4072 - val_loss: 1.9565 - val_accuracy: 0.3856\n",
      "Epoch 21/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.5444 - accuracy: 0.4069 - val_loss: 1.3195 - val_accuracy: 0.4065\n",
      "Epoch 22/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.5071 - accuracy: 0.4142 - val_loss: 1.1281 - val_accuracy: 0.4188\n",
      "Epoch 23/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4801 - accuracy: 0.4360 - val_loss: 1.3955 - val_accuracy: 0.3859\n",
      "Epoch 24/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4396 - accuracy: 0.4454 - val_loss: 1.2438 - val_accuracy: 0.4305\n",
      "Epoch 25/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.4562 - accuracy: 0.4361 - val_loss: 1.4122 - val_accuracy: 0.3798\n",
      "Epoch 26/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4799 - accuracy: 0.4343 - val_loss: 1.7286 - val_accuracy: 0.3592\n",
      "Epoch 27/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4611 - accuracy: 0.4351 - val_loss: 2.0067 - val_accuracy: 0.4076\n",
      "Epoch 28/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4249 - accuracy: 0.4478 - val_loss: 0.9949 - val_accuracy: 0.4405\n",
      "Epoch 29/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4007 - accuracy: 0.4643 - val_loss: 1.1173 - val_accuracy: 0.4533\n",
      "Epoch 30/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.3661 - accuracy: 0.4739 - val_loss: 1.0572 - val_accuracy: 0.4547\n",
      "Epoch 31/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.5258 - accuracy: 0.4292 - val_loss: 1.6865 - val_accuracy: 0.2594\n",
      "Epoch 32/150\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 1.6198 - accuracy: 0.3857 - val_loss: 1.8697 - val_accuracy: 0.3544\n",
      "Epoch 33/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4956 - accuracy: 0.4240 - val_loss: 1.7997 - val_accuracy: 0.3767\n",
      "Epoch 34/150\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 1.4095 - accuracy: 0.4568 - val_loss: 1.3835 - val_accuracy: 0.4205\n",
      "Epoch 35/150\n",
      "106/128 [=======================>......] - ETA: 1s - loss: 1.4784 - accuracy: 0.4323"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator()\n",
    "print('hh')\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
    "val_genr=gen.flow(x_val,y_val,batch_size=64)\n",
    "test_genr=gen.flow(x_test,y_test,batch_size=64)\n",
    "\n",
    "print('dd') \n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    " \n",
    "history=model.fit_generator(train_generator, steps_per_epoch=128, epochs=150\n",
    "                    ,validation_data=val_genr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBvPzoN3B7D5"
   },
   "outputs": [],
   "source": [
    "scores=model.evaluate_generator(test_genr)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face_expression_detectionl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
